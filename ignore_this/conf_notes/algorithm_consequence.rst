CONSEQUENCES OF AN INSIGHTFUL ALGORITHM
========================================

* Do we have the right to know things that people didn't INTEND to share, even if they shared the pieces that let us DERIVE that information?
* Deep Learning: Algorithms for fast, trainable, artificial neural networks

Data Mining Fail
----------------
* Target solved their "we know too much about you" issue by DISGUISING the pregnancy-focused adds.
* Shutterfly mis-targeted people they THOUGHT might be pregnant. Lots of those people were infertile or had miscarriages.
* Zuck talking about his wife's miscarriages. He's MUCH wiser now than he was 10 years ago, when VCs were throwing $$ at him.
* Facebook Year in Review

  * Eric Meyer (inadvertant algorithmic cruelty)
  * increase awareness of various failure modes
* Fitbit Sex Tracking

  * Fitbit profiles were, by default, set to PUBLIC
  * They didn't want to fix it PROPERLY, so they removed Sex Tracking
* Uber's 

  * *God View* used for 'fun' or, "Creepy Stalker View".
  * "One Night Stand" tracker
* Google Adwords: found 'black' and 'white' first names; 'black' names more likely to be shown ads suggesting a criminal background.
* Facial recognition: Google, Flickr tend to think black people are animals/gorillas. :-/
* Digital sensors today try to replicate film color balance. That color balance was based on white skin tones. So, it CONTINUES to be terrible for darker skinned people. This is from the 1950s. "Shirley Cards".